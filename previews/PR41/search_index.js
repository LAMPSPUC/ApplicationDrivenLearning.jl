var documenterSearchIndex = {"docs":
[{"location":"examples/newsvendor/#Newsvendor-Problem","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"","category":"section"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"This example shows how to use the ApplicationDrivenLearning.jl package to solve a newsvendor problem.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"The newsvendor problem is a classic inventory management problem where a company must decide how many units to produce to meet demand. The company wants to minimize the cost of holding excess inventory while also minimizing the cost of lost sales. ","category":"page"},{"location":"examples/newsvendor/#The-model","page":"Newsvendor Problem","title":"The model","text":"","category":"section"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"For this problem, both plan and assess models are defined as:","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"min cx - qy - rw \ntextst quad xyw geq 0 \ny + w leq x \ny leq d","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"The plan model will be run considering the demand d equal to the output of the forecast model, defining the policy x that will be used in the assess model. The assess model will be run considering the demand d equal to the actual demand.","category":"page"},{"location":"examples/newsvendor/#Data","page":"Newsvendor Problem","title":"Data","text":"","category":"section"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"We will model two separate items. One of the items presents a low overstocking cost and the other presents a low under-stocking cost, generating different incentives that a decision maker could explore. This is achieved manipulating the costs:","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"i=1 longrightarrow c=10 quad q = 19quad r = 9","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"i=2 longrightarrow c=10 quad q = 11quad r = 1","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"The demand series for both items will be generated using a discrete uniform distribution.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"Let's start by loading the necessary packages and defining the data.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"using Flux\nusing JuMP\nusing Random\nusing Gurobi\nusing ApplicationDrivenLearning\n\nADL = ApplicationDrivenLearning\n\n# data\nRandom.seed!(123)\nc = [10, 10]\nq = [19, 11]\nr = [9, 1]\ny_d = rand(10:100, (100, 2)) .|> Float32\nx_d = ones(100, 1) .|> Float32","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"Now, we can initialize the application driven learning model, build the plan and assess models and set the forecast model.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"# init application driven learning model\nmodel = ADL.Model()\n@variables(model, begin\n    x[i=1:2] >= 0, ADL.Policy\n    d[i=1:2], ADL.Forecast\nend)\n\n# plan model\n@variables(Plan(model), begin\n    y_plan[i=1:2] >= 0\n    w_plan[i=1:2] >= 0\nend)\n@constraints(Plan(model), begin\n    [i=1:2], y_plan[i] + w_plan[i] <= x[i].plan\n    [i=1:2], y_plan[i] <= d[i].plan\nend)\n@objective(Plan(model), Min, sum(c[i] * x[i].plan - q[i] * y_plan[i] - r[i] * w_plan[i] for i in 1:2))\n\n# assess model\n@variables(Assess(model), begin\n    y_assess[i=1:2] >= 0\n    w_assess[i=1:2] >= 0\nend)\n@constraints(Assess(model), begin\n    [i=1:2], y_assess[i] + w_assess[i] <= x[i].assess\n    [i=1:2], y_assess[i] <= d[i].assess\nend)\n@objective(Assess(model), Min, sum(c[i] * x[i].assess - q[i] * y_assess[i] - r[i] * w_assess[i] for i in 1:2))\n\nset_optimizer(model, Gurobi.Optimizer)\nset_silent(model)\n\n# forecast model\npred = Flux.Dense(1 => 2, exp)\nADL.set_forecast_model(model, pred)","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"We can check how the model performs by computing the assess cost with the initial (random) forecast model.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"julia> ADL.compute_cost(model, x_d, y_d)\n-5.118482679128647","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"Now let's train the model using the GradientMode.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"julia> gd_sol = ApplicationDrivenLearning.train!(\n    model, x_d, y_d,\n    ApplicationDrivenLearning.Options(\n        ApplicationDrivenLearning.GradientMode,\n        rule=Flux.Adam(0.1),\n        epochs=30\n    )\n)\nEpoch 1 | Time = 0.5s | Cost = -5.12\nEpoch 2 | Time = 1.0s | Cost = -6.25\nEpoch 3 | Time = 1.5s | Cost = -7.64\nEpoch 4 | Time = 2.1s | Cost = -9.33\nEpoch 5 | Time = 2.6s | Cost = -11.4\nEpoch 6 | Time = 3.1s | Cost = -13.93\nEpoch 7 | Time = 3.6s | Cost = -17.02\nEpoch 8 | Time = 4.1s | Cost = -20.82\nEpoch 9 | Time = 4.7s | Cost = -25.17\nEpoch 10 | Time = 5.2s | Cost = -29.51\nEpoch 11 | Time = 5.7s | Cost = -33.42\nEpoch 12 | Time = 6.3s | Cost = -37.56\nEpoch 13 | Time = 6.8s | Cost = -42.92\nEpoch 14 | Time = 7.5s | Cost = -50.45\nEpoch 15 | Time = 8.2s | Cost = -60.3\nEpoch 16 | Time = 8.9s | Cost = -72.4\nEpoch 17 | Time = 9.5s | Cost = -87.18\nEpoch 18 | Time = 10.2s | Cost = -105.31\nEpoch 19 | Time = 10.8s | Cost = -127.53\nEpoch 20 | Time = 11.4s | Cost = -154.36\nEpoch 21 | Time = 12.1s | Cost = -185.68\nEpoch 22 | Time = 12.8s | Cost = -222.14\nEpoch 23 | Time = 13.4s | Cost = -265.19\nEpoch 24 | Time = 14.0s | Cost = -315.45\nEpoch 25 | Time = 14.5s | Cost = -370.01\nEpoch 26 | Time = 15.1s | Cost = -425.62\nEpoch 27 | Time = 15.7s | Cost = -464.52\nEpoch 28 | Time = 16.3s | Cost = -461.25\nEpoch 29 | Time = 16.9s | Cost = -439.36\nEpoch 30 | Time = 17.5s | Cost = -419.52\nApplicationDrivenLearning.Solution(-464.5160680770874, Real[1.6317965f0, 1.7067692f0, 2.7623773f0, 0.9124785f0])\n\njulia> ADL.compute_cost(model, x_d, y_d)\n-464.5160680770874","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"After training, we can check the cost of the solution found by the gradient mode and even analyze the predictions from it.","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"julia> model.forecast(x_d[1,:])\n2-element Vector{Float32}:\n 80.977684\n 13.725394","category":"page"},{"location":"examples/newsvendor/","page":"Newsvendor Problem","title":"Newsvendor Problem","text":"As we can see, the forecast model overestimates the demand for the first item and underestimates the demand for the second item (both items average demand is 55), following the incentives from the model structure.","category":"page"},{"location":"tutorials/modes/#Training-modes","page":"Training modes","title":"Training modes","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Training a model with ApplicationDrivenLearning is done by calling the train! function. This function has a mode argument that represents the algorithm used to train the model. In this tutorial, we will show how to use the different modes and explore the trade-off between them.","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"The data used in this tutorial is the same as in the getting started tutorial so all the code shown in this page assumes that the full model (ApplicationDrivenLearning.Model) is already defined.","category":"page"},{"location":"tutorials/modes/#Bilevel-mode","page":"Training modes","title":"Bilevel mode","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"The bilevel mode mounts the bilevel optimization problem relative to training the predictive model and uses the BilevelJuMP package to solve it. For using this mode, we have to install the BilevelJuMP package, import it and set the BilevelJuMP mode (from BilevelJuMP.jl docs).","category":"page"},{"location":"tutorials/modes/#Arguments","page":"Training modes","title":"Arguments","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"optimizer: JuMP.jl optimizer used to solve the bilevel model using BilevelJuMP.jl.\nmode: The mode to use for the bilevel optimization problem. It can be any of the modes supported by the BilevelJuMP package.\nsilent: Whether to print the progress of the bilevel optimization problem.","category":"page"},{"location":"tutorials/modes/#Example","page":"Training modes","title":"Example","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"julia> import BilevelJuMP\njulia> import HiGHS\n\njulia> opt = ApplicationDrivenLearning.Options(\n    ApplicationDrivenLearning.BilevelMode,\n    optimizer = HiGHS.Optimizer,\n    mode = BilevelJuMP.FortunyAmatMcCarlMode(\n        primal_big_M = 100,\n        dual_big_M = 100,\n    )\n);\njulia> sol = ApplicationDrivenLearning.train!(model, X, Y, opt)\nRunning HiGHS 1.9.0 (git hash: 66f735e60): Copyright (c) 2024 HiGHS under MIT licence terms\nCoefficient ranges:\n  Matrix [1e+00, 2e+04]\n  Cost   [5e-01, 5e+00]\n  Bound  [1e+00, 1e+00]\n  RHS    [5e-01, 1e+02]\nAssessing feasibility of MIP using primal feasibility and integrality tolerance of       1e-06\nWARNING: Row      0 has         infeasibility of          10 from [lower, value, upper] = \n[             10;               0;              10]\nSolution has               num          max          sum\nCol     infeasibilities      0            0            0\nInteger infeasibilities      0            0            0\nRow     infeasibilities      8           20           42\nRow     residuals            0            0            0\nAttempting to find feasible solution by solving LP for user-supplied values of discrete variables\nCoefficient ranges:\n  Matrix [1e+00, 2e+04]\n  Cost   [5e-01, 5e+00]\n  Bound  [0e+00, 0e+00]\n  RHS    [5e-01, 1e+02]\nPresolving model\n12 rows, 7 cols, 24 nonzeros  0s\n6 rows, 7 cols, 12 nonzeros  0s\n4 rows, 5 cols, 8 nonzeros  0s\n4 rows, 5 cols, 8 nonzeros  0s\nPresolve : Reductions: rows 4(-32); columns 5(-28); elements 8(-80)\nSolving the presolved LP\nUsing EKK dual simplex solver - serial\n  Iteration        Objective     Infeasibilities num(sum)\n          0    -3.1250000000e+02 Ph1: 4(5623); Du: 1(0.3125) 0s\n          3     3.0000000000e+02 Pr: 0(0) 0s\nSolving the original LP from the solution after postsolve\nModel status        : Optimal\nSimplex   iterations: 3\nObjective value     :  3.0000000000e+02\nRelative P-D gap    :  0.0000000000e+00\nHiGHS run time      :          0.05\nPresolving model\n24 rows, 17 cols, 52 nonzeros  0s\n17 rows, 14 cols, 40 nonzeros  0s\n10 rows, 11 cols, 20 nonzeros  0s\n4 rows, 5 cols, 8 nonzeros  0s\n\nMIP start solution is feasible, objective value is 300\n\nSolving MIP model with:\n   4 rows\n   5 cols (0 binary, 0 integer, 0 implied int., 5 continuous)\n   8 nonzeros\n\nSrc: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point        \n\n        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work\nSrc  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts  \n InLp Confl. | LpIters     Time\n\n         0       0         0   0.00%   -inf            300                Large        0  \n    0      0         0     0.0s\n         1       0         1 100.00%   300             300                0.00%        0  \n    0      0         4     0.1s\n\nSolving report\n  Status            Optimal\n  Primal bound      300\n  Dual bound        300\n  Gap               0% (tolerance: 0.01%)\n  P-D integral      0\n  Solution status   feasible\n                    300 (objective)\n                    0 (bound viol.)\n                    0 (int. viol.)\n                    0 (row viol.)\n  Timing            0.11 (total)\n                    0.00 (presolve)\n                    0.00 (solve)\n                    0.00 (postsolve)\n  Max sub-MIP depth 0\n  Nodes             1\n  Repair LPs        0 (0 feasible; 0 iterations)\n  LP iterations     4 (total)\n                    0 (strong br.)\n                    0 (separation)\n                    0 (heuristics)\nApplicationDrivenLearning.Solution(300.0, Real[20.0f0])","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"The output shows the solution found by the optimizer. The first value is the cost of the solution and the second value is the predictive model parameters.","category":"page"},{"location":"tutorials/modes/#Pros","page":"Training modes","title":"Pros","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Is the most accurate option as it represents the bilevel optimization problem exactly.","category":"page"},{"location":"tutorials/modes/#Cons","page":"Training modes","title":"Cons","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Requires solving a MIP problem that grows in size very fast with the number of data points.\nRelies on parameters specific to the BilevelJuMP package.\nDoes not support integer variables in the plan and assess models.","category":"page"},{"location":"tutorials/modes/#Nelder-Mead-mode","page":"Training modes","title":"Nelder-Mead mode","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Uses the Nelder-Mead algorithm implemented in the Optim.jl package. This algorithm is a gradient-free optimization algorithm that does not require the gradient of the objective function and is very robust to the choice of the initial guess.","category":"page"},{"location":"tutorials/modes/#Arguments-2","page":"Training modes","title":"Arguments","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"initial_simplex: A n + 1 dimensional vector of n-dimensional vectors, where n is","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"the dimension of predictive model parameters. It will be used to start the search algorithm.","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"parameters: Used to generate parameters for the algorithm. Same parameter from","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Optim implementation of Nelder-Mead.","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Any other parameter acceptable on Optim.Options such as iterations, time_limit","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"and g_tol can be directly passed.","category":"page"},{"location":"tutorials/modes/#Example-2","page":"Training modes","title":"Example","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"julia> opt = ApplicationDrivenLearning.Options(\n    ApplicationDrivenLearning.NelderMeadMode,\n    show_trace = true\n);\njulia> sol = ApplicationDrivenLearning.train!(model, X, Y, opt)\nIter     Function value    √(Σ(yᵢ-ȳ)²)/n\n------   --------------    --------------\n     0     1.473289e+03     5.201782e+00\n * time: 0.0009999275207519531\n     1     1.473289e+03     1.560535e+01\n * time: 0.0019998550415039062\n     2     1.442079e+03     4.681610e+01\n * time: 0.003000020980834961\n     3     1.348446e+03     1.404482e+02\n * time: 0.004999876022338867\n     4     1.067550e+03     2.962982e+02\n * time: 0.006000041961669922\n     5     4.749537e+02     3.450557e+01\n * time: 0.007999897003173828\n     6     4.059426e+02     3.511205e+01\n * time: 0.009999990463256836\n     7     3.357185e+02     6.064606e-01\n * time: 0.013000011444091797\n     8     3.345056e+02     8.778015e+00\n * time: 0.018999814987182617\n     9     3.169496e+02     8.171539e+00\n * time: 0.020999908447265625\n    10     3.006065e+02     1.588013e+00\n * time: 0.021999835968017578\n    11     3.006065e+02     5.784607e-02\n * time: 0.023999929428100586\n    12     3.004908e+02     1.371613e-01\n * time: 0.026000022888183594\n    13     3.002165e+02     7.929993e-02\n * time: 0.029999971389770508\n    14     3.000579e+02     2.355957e-02\n * time: 0.03399991989135742\n    15     3.000107e+02     2.166748e-03\n * time: 0.03600001335144043\n    16     3.000064e+02     2.151543e-03\n * time: 0.03699994087219238\n    17     3.000021e+02     5.342755e-04\n * time: 0.03900003433227539\n    18     3.000010e+02     4.882812e-04\n * time: 0.039999961853027344\n    19     3.000001e+02     9.155273e-05\n * time: 0.04199981689453125\n    20     3.000001e+02     3.051758e-05\n * time: 0.046000003814697266\n    21     3.000000e+02     0.000000e+00\n * time: 0.04999995231628418\nApplicationDrivenLearning.Solution(300.0f0, Real[20.0f0])","category":"page"},{"location":"tutorials/modes/#Pros-2","page":"Training modes","title":"Pros","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Is the most general option as it can be used with basically any plan, assess and forecast model.\nDoes not require the gradient of the objective function.","category":"page"},{"location":"tutorials/modes/#Cons-2","page":"Training modes","title":"Cons","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Relies on a lot of iterations to accurately optimize the model parameters.\nDepends on the initial guess that can be given by the user or generated randomly by the Optim.jl package.","category":"page"},{"location":"tutorials/modes/#Gradient-mode","page":"Training modes","title":"Gradient mode","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"By computing the gradient of the assessed cost with respect to the forecast values, this mode propagates the gradient to the predictive model parameters, guiding the parameter update process. Since it uses the model structure end-to-end to guide training, it typically requires fewer iterations to achieve good results. However, it may suffer from known issues of gradient-based optimization methods, such as sensitivity to learning rate selection.","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"The gradient algorithm runs for a specified number of iterations, saving the best available parameter values until the end or convergence.","category":"page"},{"location":"tutorials/modes/#Arguments-3","page":"Training modes","title":"Arguments","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"rule: The optimizer for the gradient algorithm. Has to be an instance of optimization","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"rules from Flux.jl.","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"epochs: The number of iterations to run the gradient algorithm.\nbatch_size: The batch size to use for the gradient algorithm. If -1, the entire dataset is used.\nverbose: Whether to print the progress of the gradient algorithm.\ncompute_cost_every: Allows for cost computation of every sample to be run only","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"after a specified number of epochs. This enables faster iterations with the drawback of possibly missing sets of parameters with low associated cost.","category":"page"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"time_limit: The time limit for the gradient algorithm in seconds.\ng_tol: Convergence condition on the infinite norm of the gradient vector. Below, we illustrate the use of NelderMeadMode to optimize the predictive model used in the ongoing example.","category":"page"},{"location":"tutorials/modes/#Example-3","page":"Training modes","title":"Example","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"julia> opt = ApplicationDrivenLearning.Options(\n    ApplicationDrivenLearning.GradientMode,\n    rule = Flux.Descent(0.01),\n);\njulia> sol = ApplicationDrivenLearning.train!(model, X, Y, opt)\nEpoch 1 | Time = 0.0s | Cost = 1411.12\nEpoch 2 | Time = 0.0s | Cost = 1330.12\nEpoch 3 | Time = 0.1s | Cost = 1249.12\nEpoch 4 | Time = 0.1s | Cost = 1168.12\nEpoch 5 | Time = 0.1s | Cost = 1087.12\nEpoch 6 | Time = 0.1s | Cost = 1006.12\nEpoch 7 | Time = 0.2s | Cost = 925.12\nEpoch 8 | Time = 0.2s | Cost = 844.12\nEpoch 9 | Time = 0.2s | Cost = 763.12\nEpoch 10 | Time = 0.2s | Cost = 682.12\nEpoch 11 | Time = 0.2s | Cost = 601.12\nEpoch 12 | Time = 0.3s | Cost = 573.37\nEpoch 13 | Time = 0.3s | Cost = 564.37\nEpoch 14 | Time = 0.3s | Cost = 555.37\nEpoch 15 | Time = 0.3s | Cost = 546.37\nEpoch 16 | Time = 0.4s | Cost = 537.37\nEpoch 17 | Time = 0.4s | Cost = 528.37\nEpoch 18 | Time = 0.4s | Cost = 519.37\nEpoch 19 | Time = 0.4s | Cost = 510.37\nEpoch 20 | Time = 0.5s | Cost = 501.37\nEpoch 21 | Time = 0.5s | Cost = 492.37\nEpoch 22 | Time = 0.5s | Cost = 483.37\nEpoch 23 | Time = 0.5s | Cost = 474.37\nEpoch 24 | Time = 0.5s | Cost = 465.37\nEpoch 25 | Time = 0.6s | Cost = 456.37\nEpoch 26 | Time = 0.6s | Cost = 447.37\nEpoch 27 | Time = 0.6s | Cost = 438.37\nEpoch 28 | Time = 0.7s | Cost = 429.37\nEpoch 29 | Time = 0.7s | Cost = 420.37\nEpoch 30 | Time = 0.7s | Cost = 411.37\nEpoch 31 | Time = 0.7s | Cost = 402.37\nEpoch 32 | Time = 0.7s | Cost = 393.37\nEpoch 33 | Time = 0.8s | Cost = 384.37\nEpoch 34 | Time = 0.8s | Cost = 375.37\nEpoch 35 | Time = 0.8s | Cost = 366.37\nEpoch 36 | Time = 0.8s | Cost = 357.37\nEpoch 37 | Time = 0.9s | Cost = 348.37\nEpoch 38 | Time = 0.9s | Cost = 339.37\nEpoch 39 | Time = 0.9s | Cost = 330.37\nEpoch 40 | Time = 0.9s | Cost = 321.37\nEpoch 41 | Time = 1.0s | Cost = 312.38\nEpoch 42 | Time = 1.0s | Cost = 303.38\nEpoch 43 | Time = 1.0s | Cost = 305.62\nEpoch 44 | Time = 1.0s | Cost = 303.38\nEpoch 45 | Time = 1.1s | Cost = 305.62\nEpoch 46 | Time = 1.1s | Cost = 303.38\nEpoch 47 | Time = 1.1s | Cost = 305.62\nEpoch 48 | Time = 1.1s | Cost = 303.38\nEpoch 49 | Time = 1.2s | Cost = 305.62\nEpoch 50 | Time = 1.2s | Cost = 303.38\nEpoch 51 | Time = 1.2s | Cost = 305.62\nEpoch 52 | Time = 1.2s | Cost = 303.38\nEpoch 53 | Time = 1.3s | Cost = 305.62\nEpoch 54 | Time = 1.3s | Cost = 303.38\nEpoch 55 | Time = 1.3s | Cost = 305.62\nEpoch 56 | Time = 1.3s | Cost = 303.38\nEpoch 57 | Time = 1.4s | Cost = 305.62\nEpoch 58 | Time = 1.4s | Cost = 303.38\nEpoch 59 | Time = 1.4s | Cost = 305.62\nEpoch 60 | Time = 1.4s | Cost = 303.38\nEpoch 61 | Time = 1.5s | Cost = 305.62\nEpoch 62 | Time = 1.5s | Cost = 303.38\nEpoch 63 | Time = 1.5s | Cost = 305.62\nEpoch 64 | Time = 1.5s | Cost = 303.38\nEpoch 65 | Time = 1.6s | Cost = 305.62\nEpoch 66 | Time = 1.6s | Cost = 303.38\nEpoch 67 | Time = 1.6s | Cost = 305.62\nEpoch 68 | Time = 1.6s | Cost = 303.38\nEpoch 69 | Time = 1.7s | Cost = 305.62\nEpoch 70 | Time = 1.7s | Cost = 303.38\nEpoch 71 | Time = 1.7s | Cost = 305.62\nEpoch 72 | Time = 1.7s | Cost = 303.38\nEpoch 73 | Time = 1.8s | Cost = 305.62\nEpoch 74 | Time = 1.8s | Cost = 303.38\nEpoch 75 | Time = 1.8s | Cost = 305.62\nEpoch 76 | Time = 1.8s | Cost = 303.38\nEpoch 77 | Time = 1.9s | Cost = 305.62\nEpoch 78 | Time = 1.9s | Cost = 303.38\nEpoch 79 | Time = 1.9s | Cost = 305.62\nEpoch 80 | Time = 1.9s | Cost = 303.38\nEpoch 81 | Time = 2.0s | Cost = 305.62\nEpoch 82 | Time = 2.0s | Cost = 303.38\nEpoch 83 | Time = 2.0s | Cost = 305.62\nEpoch 84 | Time = 2.0s | Cost = 303.38\nEpoch 85 | Time = 2.1s | Cost = 305.62\nEpoch 86 | Time = 2.1s | Cost = 303.38\nEpoch 87 | Time = 2.1s | Cost = 305.62\nEpoch 88 | Time = 2.1s | Cost = 303.38\nEpoch 89 | Time = 2.2s | Cost = 305.62\nEpoch 90 | Time = 2.2s | Cost = 303.38\nEpoch 91 | Time = 2.2s | Cost = 305.62\nEpoch 92 | Time = 2.2s | Cost = 303.38\nEpoch 93 | Time = 2.3s | Cost = 305.62\nEpoch 94 | Time = 2.3s | Cost = 303.38\nEpoch 95 | Time = 2.3s | Cost = 305.62\nEpoch 96 | Time = 2.3s | Cost = 303.38\nEpoch 97 | Time = 2.4s | Cost = 305.62\nEpoch 98 | Time = 2.4s | Cost = 303.38\nEpoch 99 | Time = 2.4s | Cost = 305.62\nEpoch 100 | Time = 2.4s | Cost = 303.38\nApplicationDrivenLearning.Solution(303.3750343322754, Real[19.887499f0])","category":"page"},{"location":"tutorials/modes/#Pros-3","page":"Training modes","title":"Pros","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Tends to require fewer iterations to achieve good results.\nCan use different optimizers from Flux.jl and strategies such as stochastic gradient descent with small batches.","category":"page"},{"location":"tutorials/modes/#Cons-3","page":"Training modes","title":"Cons","text":"","category":"section"},{"location":"tutorials/modes/","page":"Training modes","title":"Training modes","text":"Relies on the gradient of the objective function, which can be costly to compute, sensitive to the learning rate and on the initial guess.\nDoes not support integer variables in the plan and assess models.","category":"page"},{"location":"examples/scheduling/#Minimal-Scheduling-Problem","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"","category":"section"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"This example shows how to use the ApplicationDrivenLearning.jl package to solve a minimal scheduling problem.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"In this problem, we have to define the dispatch of a single unit, considering it's operational constraints, costs and the demand. The cost for under-dispatching is 100 and the cost for over-dispatching is 20. The forecast model will be a simple linear model.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"The plan model will only assign the dispatch of the unit equal to the forecast. The assess model will apply a correction to the dispatch, considering the under-dispatching and over-dispatching costs.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"First, let's load the necessary packages.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"using Flux\nusing JuMP\nusing Gurobi\nusing ApplicationDrivenLearning\n\nADL = ApplicationDrivenLearning","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"Now, we can initialize the application driven learning model, build the plan and assess models and set the forecast model.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"# init application driven learning model\nmodel = ADL.Model()\n@variable(model, z >= 0, ADL.Policy)\n@variable(model, y, ADL.Forecast)\n\n# plan model\n@constraints(ADL.Plan(model), begin\n    z.plan == y.plan\nend)\n@objective(ADL.Plan(model), Min, 10*z.plan)\n\n# assess model\n@variables(ADL.Assess(model), begin\n    correction\n    under_dispatch >= 0\n    over_dispatch >= 0\nend)\n@constraints(ADL.Assess(model), begin\n    correction == y.assess - z.assess\n    under_dispatch >= correction\n    over_dispatch >= -correction\nend)\n@objective(ADL.Assess(model), Min, 10*y.assess + 100*under_dispatch + 20*over_dispatch)\n\n# forecast model\npredictive = Dense(1 => 1, exp; bias=false)\nADL.set_forecast_model(model, predictive)","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"We can check how the model performs by computing the assess cost with the initial (random) forecast model.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"X = ones(2, 1) .|> Float32\nY = zeros(2, 1) .|> Float32\nY[2, 1] = 2.0\nset_optimizer(model, Gurobi.Optimizer)\nset_silent(model)","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"julia> ADL.compute_cost(model, X, Y)\n99.7323203086853","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"And finally, we can train the model using the Nelder-Mead mode.","category":"page"},{"location":"examples/scheduling/","page":"Minimal Scheduling Problem","title":"Minimal Scheduling Problem","text":"julia> solution = ADL.train!(\n    model, X, Y,\n    ADL.Options(\n        ADL.NelderMeadMode,\n        iterations=100,\n        show_trace=true\n    )\n)\nIter     Function value    √(Σ(yᵢ-ȳ)²)/n \n------   --------------    --------------\n     0     9.973232e+01     2.466946e+00\n * time: 0.0\n     1     9.973232e+01     3.148899e+01\n * time: 0.006000041961669922\n     2     3.675434e+01     1.421373e+01\n * time: 0.014999866485595703\n     3     3.675434e+01     2.673199e+00\n * time: 0.0279998779296875\n     4     3.140795e+01     6.259584e-01\n * time: 0.039999961853027344\n     5     3.015603e+01     1.546907e-01\n * time: 0.04699993133544922\n     6     3.015603e+01     3.849030e-02\n * time: 0.05299997329711914\n     7     3.007905e+01     3.841400e-02\n * time: 0.05799984931945801\n     8     3.000222e+01     9.596825e-03\n * time: 0.06699991226196289\n     9     3.000222e+01     2.398491e-03\n * time: 0.07599997520446777\n    10     3.000222e+01     5.979546e-04\n * time: 0.0839998722076416\n    11     3.000103e+01     3.366484e-04\n * time: 0.08899998664855957\n    12     3.000035e+01     1.144409e-04\n * time: 0.09500002861022949\n    13     3.000012e+01     3.814697e-05\n * time: 0.10699987411499023\n    14     3.000005e+01     9.536743e-06\n * time: 0.11500000953674316\n    15     3.000003e+01     9.536743e-06\n * time: 0.12199997901916504\n    16     3.000001e+01     9.536743e-06\n * time: 0.1269998550415039\n    17     2.999999e+01     3.015783e-06\n * time: 0.13899993896484375\n    18     2.999999e+01     3.015783e-06\n * time: 0.14399981498718262\n    19     2.999998e+01     1.907349e-06\n * time: 0.15400004386901855\n    20     2.999998e+01     0.000000e+00\n * time: 0.1640000343322754\nApplicationDrivenLearning.Solution(29.99998f0, Real[0.6931467f0])\n\njulia> model.forecast(X[1,:])  # previsão final\n1-element Vector{Float32}:\n 1.999999\n\njulia> ADL.compute_cost(model, X, Y)  # custo final\n29.99998","category":"page"},{"location":"tutorials/custom_forecast/#Custom-forecast-models","page":"Custom forecast models","title":"Custom forecast models","text":"","category":"section"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"The basic approach to define a forecast model is to use a Chain from the Flux.jl package, that directly maps the input to the output. But there are cases where this approach is not enough.","category":"page"},{"location":"tutorials/custom_forecast/#Input-Output-mapping","page":"Custom forecast models","title":"Input-Output mapping","text":"","category":"section"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"The connection between predictive model outputs and plan model inputs is not always a straightforward one. Because of this, the set_forecast_model function, used to define the predictive model in the ApplicationDrivenLearning.jl package, includes the input_output_map parameter. This parameter allows users to declare an explicit mapping between the outputs produced by Flux models and the forecast variables used in the planning model. This is useful in contexts where the same prediction logic can be applied across several entities (such as production units or geographical locations), promoting model reuse and computational efficiency.","category":"page"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"Consider a scenario where the input dataset contains 3 predictive variables (for example expected temperature on location 1, expected temperature on location 2 and weekday), there are 2 forecast variables (energy demand on the two locations of interest) and the forecast model should use only the expected temperature of a location to predict it’s demand. That means we would make two predictions using the same model and concatenate those values. This can be easily achieved with a dictionary mapping the data input and forecast variable indexes.","category":"page"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"X = [\n    76 89 2;\n    72 85 3\n] # input dataset of size 2 by 3\ndem_forecast = Dense(\n    2 => 1\n) # forecast model takes 2 inputs and outputs single value\n\ninput_output_map = Dict(\n    [1, 3] => [1], # input indexes 1 and 3 map to 1st forecast variable\n    [2, 3] => [2] # input indexes 2 and 3 map to 2nd forecast variable\n)\nApplicationDrivenLearning.set_forecast_model(model, dem_forecast, input_output_map)","category":"page"},{"location":"tutorials/custom_forecast/#Multiple-Flux-models","page":"Custom forecast models","title":"Multiple Flux models","text":"","category":"section"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"The definition of the predictive model can also be done using multiple Flux models. This supports the modular construction of predictive architectures, where specialized components are trained to forecast different aspects of the problem, without the difficulty of defining custom architectures.","category":"page"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"This can be achieved providing an array of model objects and an array of dictionaries as input-output mapping to the set_forecast_model function. Using the context from previous example, let’s assume there is an additional variable that has to be predicted to each location but not variable on time (that is, on dataset samples). This can be achieved defining an additional model that maps a constant input value to the correct output indexes.","category":"page"},{"location":"tutorials/custom_forecast/","page":"Custom forecast models","title":"Custom forecast models","text":"X = [\n    76 89 2 1;\n    72 85 3 1\n] # input dataset of size 2 by 4\ndem_forecast = Dense(\n    2 => 1\n) # demand forecast model takes 2 inputs and outputs single value\naux_forecast = Dense(\n    1 => 2\n) # auxiliar forecast model takes 1 input and outputs 2 values\nforecast_objs = [dem_forecast, aux_forecast]\ninput_output_map = [\n    Dict(\n        [1, 3] => [1],\n        [2, 3] => [2]\n    ), # input indexes 1,2,3 are used to compute forecast vars 1,2 with 1st Flux.Dense object\n    Dict(\n        [4] => [3, 4]\n    ), # input index 4 is used to compute forecast vars 3,4 with 2nd Flux.Dense object\n]\nApplicationDrivenLearning.set_forecast_model(model, forecast_objs, input_output_map)","category":"page"},{"location":"tutorials/getting_started/#Getting-started-with-ApplicationDrivenLearning","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"This is a quick introduction modeling and training end-to-end forecast models with ApplicationDrivenLearning.","category":"page"},{"location":"tutorials/getting_started/#A-first-example","page":"Getting started with ApplicationDrivenLearning","title":"A first example","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"We will train a energy load predictive model that is applied to a one-hour agead generation planning problem in a power system consisting of a single plant with the following characteristics: a production capacity of 4 MW and a generation cost of R10/MWh.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"The available data is very limited: we don't have any auxiliar variable and just two samples of past demand.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Here is the complete code to model, train and extract the parameters of the predictive model:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"using JuMP\nusing Flux\nimport HiGHS\nusing ApplicationDrivenLearning\n\n# data\nX = reshape([1 1], (2, 1)) .|> Float32\nY = reshape([10 20], (2, 1)) .|> Float32\n\n# main model and policy / forecast variables\nmodel = ApplicationDrivenLearning.Model()\n@variables(model, begin\n    z, ApplicationDrivenLearning.Policy\n    θ, ApplicationDrivenLearning.Forecast\nend)\n\n# plan model\n@variables(ApplicationDrivenLearning.Plan(model), begin\n    c1 ≥ 0\n    c2 ≥ 0\nend)\n@constraints(ApplicationDrivenLearning.Plan(model), begin\n    c1 ≥ 100 * (θ.plan-z.plan)\n    c2 ≥ 20 * (z.plan-θ.plan)\nend)\n@objective(ApplicationDrivenLearning.Plan(model), Min, 10*z.plan + c1 + c2)\n\n# assess model\n@variables(ApplicationDrivenLearning.Assess(model), begin\n    c3 ≥ 0\n    c4 ≥ 0\nend)\n@constraints(ApplicationDrivenLearning.Assess(model), begin\n    c3 ≥ 100 * (θ.assess-z.assess)\n    c4 ≥ 20 * (z.assess-θ.assess)\nend)\n@objective(ApplicationDrivenLearning.Assess(model), Min, 10*z.assess + c3 + c4)\n\n# basic setting\nset_optimizer(model, HiGHS.Optimizer)\nset_silent(model)\n\n# forecast model\nnn = Chain(Dense(1 => 1; bias=false))\nApplicationDrivenLearning.set_forecast_model(model, nn)\n\n# training the full model\nsolution = ApplicationDrivenLearning.train!(\n    model,\n    X,\n    Y,\n    ApplicationDrivenLearning.Options(\n        ApplicationDrivenLearning.NelderMeadMode\n    )\n)\n\n# getting predictions\npred = model.forecast(X')\n\n# extracting solution\nprintln(solution.params)","category":"page"},{"location":"tutorials/getting_started/#Step-by-step","page":"Getting started with ApplicationDrivenLearning","title":"Step-by-step","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Once installed, the necessary packages can be loaded into julia:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"using JuMP\nusing Flux\nusing ApplicationDrivenLearning","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"We have to include a solver for solving the optimization models. In this case, we load HiGHS:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"using HiGHS","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"As explained, the data used to train the model is very limited, composed of only two samples of energy demand. Values of one are used as input data, without adding any real additional information to the model. Both X and Y values are transformed to Float32 type to match Flux parameters.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"X = reshape([1 1], (2, 1)) .|> Float32\nY = reshape([10 20], (2, 1)) .|> Float32","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Just like regular JuMP, ApplicationDrivenLearning has a Model function to initialize an empty model. After initializing, we can declare the policy and forecast variables.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Policy variables represent decision variables that should be maintained from the Plan to the Assess model.\nForecast variables represent future values relevant to the problem. They are replaced by forecast output values in the planning step and fixed as realized values (from the Y matrix) in the assessment step.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"For our problem, the policy variable z represents the generation and forecast variable θ represents the demand.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"model = ApplicationDrivenLearning.Model()\n@variables(model, begin\n    z, ApplicationDrivenLearning.Policy\n    θ, ApplicationDrivenLearning.Forecast\nend)","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"To populate the plan model, we follow a syntax very similar to the JuMP package, with the addition of a suffix on policy and forecast variables.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"We declare additional variables c1 and c2 to model the overestimation and underestimation costs, that are added to the generation cost in the objective function. ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"@variables(ApplicationDrivenLearning.Plan(model), begin\n    c1 ≥ 0\n    c2 ≥ 0\nend)\n@constraints(ApplicationDrivenLearning.Plan(model), begin\n    c1 ≥ 100 * (θ.plan-z.plan)\n    c2 ≥ 20 * (z.plan-θ.plan)\nend)\n@objective(ApplicationDrivenLearning.Plan(model), Min, 10*z.plan + c1 + c2)","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"The assess model can be declared in a similar way.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"@variables(ApplicationDrivenLearning.Assess(model), begin\n    c3 ≥ 0\n    c4 ≥ 0\nend)\n@constraints(ApplicationDrivenLearning.Assess(model), begin\n    c3 ≥ 100 * (θ.assess-z.assess)\n    c4 ≥ 20 * (z.assess-θ.assess)\nend)\n@objective(ApplicationDrivenLearning.Assess(model), Min, 10*z.assess + c3 + c4)","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"We need to associate the model with an optimizer that can solve the plan and assess models. For this case, we use the HiGHS optimizer. We also set the model to silent mode to avoid excessive outputs from the solve iterations.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"set_optimizer(model, HiGHS.Optimizer)\nset_silent(model)","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"A simple forecast model with only one parameter can be defined as a Flux.Dense layer with just 1 weight and no bias. We can associate the predictive model with our ApplicationDrivenLearning model only if its output size matches the number of declared forecast variables.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"nn = Chain(Dense(1 => 1; bias=false))\nApplicationDrivenLearning.set_forecast_model(model, nn)","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Finally, the full model is trained using the NelderMeadMode. For using this mode, it is necessary to install the Optim package previously, but it doesn't need to be installed.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"solution = ApplicationDrivenLearning.train!(\n    model,\n    X,\n    Y,\n    ApplicationDrivenLearning.Options(\n        ApplicationDrivenLearning.NelderMeadMode\n    )\n)","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Now we can easily make new predictions with the trained model:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"julia> pred = model.forecast(X')\n1×2 Matrix{Float32}:\n 20.0  20.0","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"Compute the assess cost for each data sample:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"julia> ApplicationDrivenLearning.compute_cost(model, X, Y, false, false)\n2-element Vector{Float64}:\n 400.0\n 200.0","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"And also extract the parameters from the trained model:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting started with ApplicationDrivenLearning","title":"Getting started with ApplicationDrivenLearning","text":"julia> solution.params\n1-element Vector{Real}:\n 20.0f0","category":"page"},{"location":"reference/#API","page":"API Reference","title":"API","text":"","category":"section"},{"location":"reference/","page":"API Reference","title":"API Reference","text":"This section documents the ApplicationDrivenLearning API.","category":"page"},{"location":"reference/#Constructors","page":"API Reference","title":"Constructors","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.Model","page":"API Reference","title":"ApplicationDrivenLearning.Model","text":"Model <: JuMP.AbstractModel\n\nCreate an empty ApplicationDrivenLearning.Model with empty plan and assess models, missing forecast model and default settings.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.PredictiveModel","page":"API Reference","title":"ApplicationDrivenLearning.PredictiveModel","text":"PredictiveModel(networks, input_output_map, input_size, output_size)\n\nCreates a predictive (forecast) model for the AppDrivenLearning module from Flux models and input/output information.\n\n...\n\nArguments\n\nnetworks: array of Flux models to be used.\ninput_output_map::Vector{Dict{Vector{Int}, Vector{Int}}}: array in the same ordering as networks of mappings from input indexes to output indexes on which the models should be applied.\ninput_size::Int: size of the input vector.\noutput_size::Int: size of the output vector. ...\n\nExample\n\njulia> pred_model = PredictiveModel(\n        [Flux.Dense(1 => 1), Flux.Dense(3 => 2)],\n        [\n            Dict([1] => [1], [1] => [2]),\n            Dict([1,2,3] => [3,4], [1,4,5] => [5,6])\n        ],\n        5,\n        6\n    );\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.Plan","page":"API Reference","title":"ApplicationDrivenLearning.Plan","text":"Upper(model::ApplicationDrivenLearning.Model)\n\nCreate a reference to the plan model of an application driven learning model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.Assess","page":"API Reference","title":"ApplicationDrivenLearning.Assess","text":"Assess(model::ApplicationDrivenLearning.Model)\n\nCreate a reference to the assess model of an application driven learning model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#JuMP-variable-types","page":"API Reference","title":"JuMP variable types","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.Policy","page":"API Reference","title":"ApplicationDrivenLearning.Policy","text":"Policy{T}\n\nPolicy variable type that holds plan and assess variables.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.Forecast","page":"API Reference","title":"ApplicationDrivenLearning.Forecast","text":"Forecast{T}\n\nForecast variable type that holds plan and assess variables.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Structs","page":"API Reference","title":"Structs","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.Options","page":"API Reference","title":"ApplicationDrivenLearning.Options","text":"Options(mode; params...)\n\nOptions struct to hold optimization mode and mode parameters.\n\n...\n\nExample\n\noptions = Options(\n    GradientMode;\n    rule = Optim.RMSProp(0.01),\n    epochs = 100,\n    batch_size = 10,\n)\n\n...\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.Solution","page":"API Reference","title":"ApplicationDrivenLearning.Solution","text":"Solution\n\nA struct to store the result of the optimisation process with final cost and solution.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Modes","page":"API Reference","title":"Modes","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.NelderMeadMode","page":"API Reference","title":"ApplicationDrivenLearning.NelderMeadMode","text":"NelderMeadMode <: AbstractOptimizationMode\n\nUsed to solve the application driven learning training problem using the Nelder-Mead optimization method implementation from Optim.jl package.\n\n...\n\nParameters\n\ninitial_simplex is the initial simplex of solutions to be applied.\nparameters is the parameters to be applied to the Nelder-Mead optimization method. ...\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.GradientMode","page":"API Reference","title":"ApplicationDrivenLearning.GradientMode","text":"GradientMode <: AbstractOptimizationMode\n\nUsed to solve the application driven learning training problem using the gradient optimization method\n\n...\n\nParameters\n\nrule is the optimiser object to be used in the gradient optimization process.\n'epochs' is the number of epochs to be used in the gradient optimization process.\n'batch_size' is the batch size to be used in the gradient optimization process.\n'verbose' is the flag of whether to print the training process.\n'computecostevery' is the epoch frequency for computing the cost and evaluating best solution.\n'time_limit' is the time limit for the training process. ...\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.NelderMeadMPIMode","page":"API Reference","title":"ApplicationDrivenLearning.NelderMeadMPIMode","text":"NelderMeadMPIMode <: AbstractOptimizationMode\n\nMPI implementation of NelderMeadMode.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.GradientMPIMode","page":"API Reference","title":"ApplicationDrivenLearning.GradientMPIMode","text":"GradientMPIMode <: AbstractOptimizationMode\n\nMPI implementation of GradientMode.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ApplicationDrivenLearning.BilevelMode","page":"API Reference","title":"ApplicationDrivenLearning.BilevelMode","text":"BilevelMode <: AbstractOptimizationMode\n\nUsed to solve the application driven learning training problem as a bilevel optimization problem by using the BilevelJuMP.jl package.\n\n...\n\nParameters\n\noptimizer::Function is equivalent to solver in BilevelJuMP.BilevelModel.\nsilent::Bool is equivalent to silent in BilevelJuMP.BilevelModel.\nmode::Union{Nothing, BilevelJuMP.BilevelMode} is equivalent to mode in BilevelJuMP.BilevelModel. ...\n\n\n\n\n\n","category":"type"},{"location":"reference/#Attributes-getters-and-setters","page":"API Reference","title":"Attributes getters and setters","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.plan_policy_vars","page":"API Reference","title":"ApplicationDrivenLearning.plan_policy_vars","text":"Returns vector of policy variables from plan model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.assess_policy_vars","page":"API Reference","title":"ApplicationDrivenLearning.assess_policy_vars","text":"Returns vector of policy variables from assess model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.plan_forecast_vars","page":"API Reference","title":"ApplicationDrivenLearning.plan_forecast_vars","text":"Returns vector of forecast variables from plan model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.assess_forecast_vars","page":"API Reference","title":"ApplicationDrivenLearning.assess_forecast_vars","text":"Returns vector of forecast variables from assess model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.set_forecast_model","page":"API Reference","title":"ApplicationDrivenLearning.set_forecast_model","text":"Sets Chain, Dense or custom PredictiveModel object as forecast model.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.extract_params","page":"API Reference","title":"ApplicationDrivenLearning.extract_params","text":"extract_params(model)\n\nExtract the parameters of a PredictiveModel into a single vector.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.apply_params","page":"API Reference","title":"ApplicationDrivenLearning.apply_params","text":"apply_params(model, θ)\n\nReturn model after fixing the parameters from an adequate vector of parameters.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Flux-attributes-getters-and-setters","page":"API Reference","title":"Flux attributes getters and setters","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.extract_flux_params","page":"API Reference","title":"ApplicationDrivenLearning.extract_flux_params","text":"extract_flux_params(model)\n\nExtract the parameters of a Flux model (Flux.Chain or Flux.Dense) into a single vector.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.fix_flux_params_single_model","page":"API Reference","title":"ApplicationDrivenLearning.fix_flux_params_single_model","text":"fix_flux_params_single_model(model, θ)\n\nReturn model after fixing the parameters from an adequate vector of parameters.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.fix_flux_params_multi_model","page":"API Reference","title":"ApplicationDrivenLearning.fix_flux_params_multi_model","text":"fix_flux_params_multi_model(models, θ)\n\nReturn iterable of models after fixing the parameters from an adequate vector of parameters.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.has_params","page":"API Reference","title":"ApplicationDrivenLearning.has_params","text":"has_params(layer)\n\nCheck if a Flux layer has parameters.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.apply_gradient!","page":"API Reference","title":"ApplicationDrivenLearning.apply_gradient!","text":"apply_gradient!(model, dCdy, X, rule)\n\nApply a gradient vector to the model parameters.\n\n...\n\nArguments\n\nmodel::PredictiveModel: model to be updated.\ndCdy::Vector{<:Real}: gradient vector.\nX::Matrix{<:Real}: input data.\nrule: Optimisation rule. ...\n\n\n\n\n\n","category":"function"},{"location":"reference/#Other-functions","page":"API Reference","title":"Other functions","text":"","category":"section"},{"location":"reference/#ApplicationDrivenLearning.forecast","page":"API Reference","title":"ApplicationDrivenLearning.forecast","text":"forecast(model, X)\n\nReturn forecast model output for given input.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.compute_cost","page":"API Reference","title":"ApplicationDrivenLearning.compute_cost","text":"compute_cost(model, X, Y, with_gradients=false)\n\nCompute the cost function (C) based on the model predictions and the true values.\n\n...\n\nArguments\n\nmodel::ApplicationDrivenLearning.Model: model to evaluate.\nX::Matrix{<:Real}: input data.\nY::Matrix{<:Real}: true values.\nwith_gradients::Bool=false: flag to compute and return gradients. ...\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.train!","page":"API Reference","title":"ApplicationDrivenLearning.train!","text":"train!(model, X, y, options)\n\nTrain model using given data and options.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.build_plan_model_forecast_params","page":"API Reference","title":"ApplicationDrivenLearning.build_plan_model_forecast_params","text":"Creates new forecast variables to plan model using MOI.Parameter and new constraint fixing to original forecast variables.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.build_assess_model_policy_constraint","page":"API Reference","title":"ApplicationDrivenLearning.build_assess_model_policy_constraint","text":"Creates new constraint to assess model that fixes policy variables.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ApplicationDrivenLearning.build","page":"API Reference","title":"ApplicationDrivenLearning.build","text":"Calls functions that set new variables and constraints that are necessary to cost computation.\n\n\n\n\n\n","category":"function"},{"location":"#ApplicationDrivenLearning.jl-Documentation","page":"Home","title":"ApplicationDrivenLearning.jl Documentation","text":"","category":"section"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ApplicationDrivenLearning.jl is a Julia package for training time series forecast models using the application driven learning framework, that connects the optimization problem final cost with predictive model parameters in order to achieve the best model for a given application.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install ApplicationDrivenLearning with Julia's built-in package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> import Pkg\n\njulia> Pkg.add(\"ApplicationDrivenLearning\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For properly modelling plan, assess and predictive models, you will also need JuMP and Flux packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> Pkg.add(\"JuMP\")\njulia> Pkg.add(\"Flux\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, for actually training the model, you will need to be able to solve the optimization models and the appropriate package depending on the training mode.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Learn the basics of JuMP and Julia in the JuMP documentation\nFollow the tutorials in this manual","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you need help, please open a GitHub issue.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ApplicationDrivenLearning.jl is licensed under the MIT License.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PRs such as adding new training modes and fixing bugs are very welcome!\nFor nontrivial changes, you'll probably want to first discuss the changes via issue.","category":"page"}]
}
